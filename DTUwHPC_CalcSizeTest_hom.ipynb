{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7082e161-3124-4500-a3b3-b3783e789c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# DTU Master Project #################\n",
    "################# Jupyter Notebook script to be converted to .py file to run in HPC #################\n",
    "import warnings\n",
    "import numpy as np\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.utils.data import clear_download_cache\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.modeling.models import Sersic2D\n",
    "from astropy.modeling.models import Gaussian2D\n",
    "from astropy.visualization import LogStretch\n",
    "from astropy.convolution import convolve, Gaussian2DKernel\n",
    "from astropy.modeling.models import custom_model\n",
    "from astropy.modeling import Fittable2DModel\n",
    "from scipy.special import gammaincinv\n",
    "from scipy.special import gamma\n",
    "from astropy.io import fits\n",
    "from IPython.display import Image\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import os\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.io.fits as pyfits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.nddata import Cutout2D\n",
    "import scipy.ndimage as nd\n",
    "import sep\n",
    "import time\n",
    "from pysersic import check_input_data\n",
    "from pysersic.results import plot_image\n",
    "from pysersic import FitSingle\n",
    "from pysersic.loss import student_t_loss, gaussian_loss\n",
    "from jax.random import PRNGKey # Need to use a seed to start jax's random number generation\n",
    "from pysersic.results import plot_residual\n",
    "from pysersic.priors import autoprior\n",
    "from pysersic.multiband import FitMultiBandPoly\n",
    "import jax\n",
    "import arviz as az\n",
    "import grizli\n",
    "import grizli.catalog\n",
    "from grizli import utils\n",
    "import eazy\n",
    "import eazy.hdf5\n",
    "import scipy.stats as st\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib as mpl\n",
    "import csv\n",
    "import pandas as pd\n",
    "import asdf\n",
    "import corner\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as mticker\n",
    "from pysersic.priors import PySersicSourcePrior, estimate_sky\n",
    "from skimage.measure import block_reduce\n",
    "from pysersic import FitMulti, PySersicMultiPrior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e5d0f31-8aa8-4380-8a56-9118009f2532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c48298-a6a1-45e2-b98e-7eab6efcb295",
   "metadata": {},
   "source": [
    "# Definition of functions to load and save files + Full wht and Full exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0819a50c-5e36-4cce-8c7e-c7a606405c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcSize:\n",
    "    def load_ims(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, n, Path_to_cutout):\n",
    "        start = time.time()\n",
    "        # Decide whether the interest is on science or all images\n",
    "        if n == 0:\n",
    "            names = ['sci', 'wht', 'exp']\n",
    "        else: names = ['sci']\n",
    "            \n",
    "        img = {}\n",
    "        Im_output = {}\n",
    "        ra = RA\n",
    "        dec = DEC\n",
    "        imsize = IMSIZE\n",
    "        if len(ra) != len(dec) or len(ra) != len(imsize) or len(Nc) != len(ra):\n",
    "            warnings.warn('Size of RA, DEC or IMSIZE do not correspond. It must be len(RA) = len(DEC) = len(IMSIZE) = len(Nc).')\n",
    "        if len(Nc) == 1 and len(RA) != 1:\n",
    "            ra = np.array([RA])\n",
    "        if len(Nc) == 1 and len(DEC) != 1:\n",
    "            dec = np.array([DEC]) \n",
    "        if len(Nc) == 1 and len(IMSIZE) != 1:\n",
    "            imsize = np.array([IMSIZE]) \n",
    "        if len(Nc) == 1 and len(Nfilter) != 1:\n",
    "            Nfilter = np.array([Nfilter])\n",
    "        # Cutout size must be given. If null hypothesis is assumed, the user puts zero in the corresponding list position: the code will make an estimate of a suitable size \n",
    "        for i in range(0, len(Nc)):\n",
    "            if any(imsize[i][k] == 0 for k in range(len(imsize[i]))) or len(imsize[i]) == 0:\n",
    "                imsize[i] = 3*np.ones(len(ra[Nc[i]]))\n",
    "            \n",
    "        Filters = {}  \n",
    "        for ext in names:\n",
    "            Im_output[ext] = {}\n",
    "            for l in range(0, len(Nc)):\n",
    "                Im_output[ext][Nc[l]] = {}\n",
    "                for m in range(0, len(Nfilter[l])):\n",
    "                    F = Nfilter[l][m]\n",
    "                    Im_output[ext][Nc[l]][F] = []\n",
    "                    ### Prepare file\n",
    "                    _file = N0 + Nc[l] + '-grizli-' + Nv[l] + '-' + F + '_drc_' + ext + '.fits.gz'\n",
    "                    print('Opening file ', _file,' ...')\n",
    "                    local_path = download_file(_file, cache=True)\n",
    "                    img[ext] = fits.open(local_path)\n",
    "                    wcs = WCS(img[ext][0])\n",
    "                    header = img[ext][0].header\n",
    "                    print('Cutting file... ')\n",
    "                    ### Cut file\n",
    "                    ### GDS and GDN have different pixel sizes in arcsec for different wavelengths, thus normalize the size of the cutouts\n",
    "                    for k in range(0, len(ra[l])):\n",
    "                        if F in ['f200w-clear', 'f150w-clear'] and Nc[l] in ['gdn', 'gds']:\n",
    "                            # Use N*0.5 if you wish to de-normalize it. In this case, normalization is applied.\n",
    "                            side = u.Quantity(0.5*imsize[l][k]*u.arcsec, 0.5*imsize[l][k]*u.arcsec)\n",
    "                            pos = SkyCoord(ra[l][k]*u.deg, dec[l][k]*u.deg,frame='fk5')\n",
    "                            cutout = Cutout2D(img[ext][0].data, position=pos, size=side, wcs=wcs)\n",
    "                            updated_header = cutout.wcs.to_header()\n",
    "                        else:\n",
    "                            side = u.Quantity(imsize[l][k]*u.arcsec, imsize[l][k]*u.arcsec)\n",
    "                            pos = SkyCoord(ra[l][k]*u.deg, dec[l][k]*u.deg,frame='fk5')\n",
    "                            cutout = Cutout2D(img[ext][0].data, position=pos, size=side, wcs=wcs)\n",
    "                            updated_header = cutout.wcs.to_header()\n",
    "                        #print('Done.')\n",
    "                        ### ----------------\n",
    "                        if header.get('PHOTMJSR') == None:\n",
    "                            ## In case of missing parameter, it happened once... ##\n",
    "                            header['PHOTMJSR'] = 0.4\n",
    "                        updated_header['PHOTMJSR'] = header['PHOTMJSR']\n",
    "                        updated_header['PHOTSCAL'] = header['PHOTSCAL']\n",
    "                        if 'OPHOTFNU' in header:\n",
    "                            updated_header['OPHOTFNU'] = header['OPHOTFNU']\n",
    "                            updated_header['PHOTFNU'] = header['PHOTFNU']\n",
    "                        # --- Define cutout name ---\n",
    "                        Cname = F + '_' + str(ra[l][k]) + '_' + str(dec[l][k])\n",
    "                        try:\n",
    "                            os.makedirs(f'{Path_to_cutout}')\n",
    "                            print(f\"Directory '{Path_to_cutout}' created successfully.\")\n",
    "                        except FileExistsError:\n",
    "                            print(f\"Directory '{Path_to_cutout}' already exists.\")\n",
    "                        except PermissionError:\n",
    "                            print(f\"Permission denied: Unable to create '{Path_to_cutout}'.\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"An error occurred: {e}\")\n",
    "                            \n",
    "                        cutout_name = Path_to_cutout + Cname + '_' + ext + '.fits'\n",
    "                        print('Saving file ', cutout_name,' ...')\n",
    "                        cutout_hdul = fits.PrimaryHDU(data = cutout.data, header = updated_header)\n",
    "                        cutout_hdul.writeto(cutout_name, overwrite = True)\n",
    "    \n",
    "                        #filename = f'cutout_'+Cname+'_'+ext+'.fits'\n",
    "                        Im_temp = fits.open(cutout_name)\n",
    "    \n",
    "                        Im_output[ext][Nc[l]][F].append((Im_temp, str(ra[l][k])+'_'+str(dec[l][k])))\n",
    "                    ## Clear cache at every filter step    \n",
    "                    clear_download_cache()\n",
    "                    ##\n",
    "                        #cutout filter name, field name and extension are loaded together the image\n",
    "        end = time.time()\n",
    "        length = end - start\n",
    "        print('Loading has implied ', length/60, ' minutes to run')\n",
    "        return Im_output\n",
    "        \n",
    "    def GetMask(N0, Nc, Nfilter, ra, dec, Path_to_cutout):\n",
    "        for i in range(0, len(Nc)):\n",
    "            for j in range(0, len(Nfilter[i])):\n",
    "                F = Nfilter[i][j]\n",
    "                for k in range(0, len(ra[i])):\n",
    "                    Cname = F + '_' + str(ra[i][k]) + '_' + str(dec[i][k])\n",
    "                    img = fits.open(Path_to_cutout + Cname + \"_sci.fits\")[0].data.astype(\"f4\")\n",
    "                    rms = np.load(Path_to_cutout + Cname + \"_sigma.npy\")\n",
    "                    ## Derive a mask based on the chosen band\n",
    "                    cat, seg = sep.extract(img, thresh = 3., err = rms, segmentation_map = True,)\n",
    "                    c = round(len(rms)*0.5)\n",
    "                    obj_id = seg[c,c]\n",
    "                    mask = seg.copy()\n",
    "                    mask[np.where(seg ==obj_id)] = 0\n",
    "                    mask[mask>=1] = 1\n",
    "                    # --- Path needs to be given by the users\n",
    "                    np.save(Path_to_cutout + Cname + \"_mask.npy\", mask)\n",
    "                    print(Path_to_cutout + Cname + \"_mask.npy\")\n",
    "                ## Clear cache at every filter step. Useful to free memory and avoid self-kill   \n",
    "                clear_download_cache()\n",
    "                ##\n",
    "                \n",
    "    def GetExpWht(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, Path_to_cutout):\n",
    "    # Grow the exposure map to the original frame\n",
    "        img = CalcSize.load_ims(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, 0, Path_to_cutout)\n",
    "        if img == 0:\n",
    "            return print('Deprecated')\n",
    "        img['Full exp'] = {}\n",
    "        img['Full wht'] = {}\n",
    "        for l in range(0, len(Nc)):\n",
    "            img['Full exp'][Nc[l]] = {}\n",
    "            img['Full wht'][Nc[l]] = {}\n",
    "            for F in img['sci'][Nc[l]]:\n",
    "                img['Full exp'][Nc[l]][F] = []\n",
    "                img['Full wht'][Nc[l]][F] = []\n",
    "                for i in range(0, len(img['sci'][Nc[l]][F])):\n",
    "                    full_exp = np.zeros(img['sci'][Nc[l]][F][i][0][0].data.shape, dtype=int)\n",
    "                    try:\n",
    "                        full_exp[1::4, 1::4] += img['exp'][Nc[l]][F][i][0][0].data * 1\n",
    "                    except ValueError:\n",
    "                        full_exp[0::4, 0::4] += img['exp'][Nc[l]][F][i][0][0].data * 1\n",
    "                    full_exp = nd.maximum_filter(full_exp, 4)\n",
    "                    \n",
    "                    # Make Full exp map\n",
    "                    img['Full exp'][Nc[l]][F].append((fits.HDUList([fits.PrimaryHDU(data=full_exp)]), \n",
    "                                        img['exp'][Nc[l]][F][i][1]))\n",
    "                    header = img['exp'][Nc[l]][F][i][0][0].header\n",
    "                    # Multiplicative factors that have been applied since the original count-rate images\n",
    "                    phot_scale = 1.\n",
    "                    for k in ['PHOTMJSR','PHOTSCAL']:\n",
    "                        print(f'{k} {header[k]:.3f}')\n",
    "                        phot_scale /= header[k]\n",
    "                    if 'OPHOTFNU' in header:\n",
    "                        phot_scale *= header['PHOTFNU'] / header['OPHOTFNU']\n",
    "                    # \"effective_gain\" = electrons per DN of the mosaic\n",
    "                    effective_gain = ( phot_scale * full_exp )\n",
    "                    # Poisson variance in mosaic DN\n",
    "                \n",
    "                    if np.min(np.abs(effective_gain)) == 0:\n",
    "                        effective_gain = effective_gain + 1e-6\n",
    "                    var_poisson_dn = np.maximum(img['sci'][Nc[l]][F][i][0][0].data, 0) / effective_gain\n",
    "                    # Original variance from the `wht` image = RNOISE + BACKGROUND\n",
    "                    if np.min(np.abs(img['wht'][Nc[l]][F][i][0][0].data))==0:\n",
    "                        img['wht'][Nc[l]][F][i][0][0].data = img['wht'][Nc[l]][F][i][0][0].data + 1e-6\n",
    "                    \n",
    "                    var_wht = 1 / img['wht'][Nc[l]][F][i][0][0].data\n",
    "                    # New total variance\n",
    "                    var_total = var_wht + var_poisson_dn\n",
    "                    full_wht = 1 / var_total\n",
    "                    # Null weights\n",
    "                    full_wht[var_total <= 0] = 0\n",
    "                    img['Full wht'][Nc[l]][F].append(( fits.HDUList([fits.PrimaryHDU(data = full_wht, header = img['wht'][Nc[l]][F][i][0][0].header)]), \n",
    "                                            img['wht'][Nc[l]][F][i][1]))\n",
    "                    sigma = np.where(img[\"Full wht\"][Nc[l]][F][i][0][0].data > 0, 1 / np.sqrt(img[\"Full wht\"][Nc[l]][F][i][0][0].data), 0.1)\n",
    "                    np.save(Path_to_cutout + F +'_'+ img['wht'][Nc[l]][F][i][1] + \"_sigma.npy\", sigma)\n",
    "                    print(Path_to_cutout + F +'_'+ img['wht'][Nc[l]][F][i][1] + \"_sigma.npy\")\n",
    "                print('Making masks... ')\n",
    "        clear_download_cache()\n",
    "        CalcSize.GetMask(N0, Nc, Nfilter, RA, DEC, Path_to_cutout)\n",
    "        return img\n",
    "    \n",
    "    def GetSize(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, psf_path, quick_size, plot_im_mask_psf, plot_resid, prior_sel, prior_type, Path_to_cutout, profile):\n",
    "        start = time.time()\n",
    "        ra = RA\n",
    "        dec = DEC\n",
    "        imsize = IMSIZE\n",
    "        if len(ra) != len(dec) or len(ra) != len(imsize) or len(Nc) != len(ra):\n",
    "            warnings.warn('Size of RA, DEC or IMSIZE do not correspond. It must be len(RA) = len(DEC) = len(IMSIZE) = len(Nc).')\n",
    "        if len(Nc) == 1 and len(RA) != 1:\n",
    "            ra = np.array([RA])\n",
    "        if len(Nc) == 1 and len(DEC) != 1:\n",
    "            dec = np.array([DEC]) \n",
    "        if len(Nc) == 1 and len(IMSIZE) != 1:\n",
    "            imsize = np.array([IMSIZE]) \n",
    "        if len(Nc) == 1 and len(Nfilter) != 1:\n",
    "            Nfilter = np.array([Nfilter])\n",
    "        # Create  the directory to store asdf files\n",
    "        asdf_store_name = '/work3/s240096/DTU_project/asdf_files_multisource'\n",
    "        try:\n",
    "            os.makedirs(asdf_store_name)\n",
    "            print(f\"Directory asdf_files created successfully.\")\n",
    "        except FileExistsError:\n",
    "            print(f\"Directory asdf_files already exists.\")\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Unable to create asdf_files.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        #######################################################\n",
    "        ## Comment the following line if files already exist ##\n",
    "        #######################################################\n",
    "        im = CalcSize.GetExpWht(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE,Path_to_cutout)\n",
    "        \n",
    "        for i in range(0, len(Nc)):\n",
    "            rkey = jax.random.PRNGKey(i)\n",
    "            for j in range(0, len(Nfilter[i])):\n",
    "                F = Nfilter[i][j]\n",
    "                # Create the directory for the residual plots\n",
    "                directory_name = f'/work3/s240096/DTU_project/residual_plots_multisource/{F}'\n",
    "                cwd = os.getcwd()\n",
    "                try:\n",
    "                    os.makedirs(f'{directory_name}')\n",
    "                    print(f\"Directory '{directory_name}' created successfully.\")\n",
    "                except FileExistsError:\n",
    "                    print(f\"Directory '{directory_name}' already exists.\")\n",
    "                except PermissionError:\n",
    "                    print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    \n",
    "                for k in range(0, len(ra[i])):\n",
    "                    Cname = F + '_' + str(ra[i][k]) +'_'+ str(dec[i][k])\n",
    "                    ##############################################################\n",
    "                    ## Comment the following line if cutout files already exist ##\n",
    "                    ##############################################################\n",
    "                    image = im['sci'][Nc[i]][F][k][0][0].data.astype(\"f4\")\n",
    "                    ##################################################################\n",
    "                    ## Uncomment the following two lines if the files already exist ##\n",
    "                    ##################################################################\n",
    "                    # image = fits.open(Path_to_cutout + Cname + '_' + 'sci' + '.fits')\n",
    "                    # image = image[0].data.astype(\"f4\")\n",
    "                    ##################################################################\n",
    "                    mask = np.load(Path_to_cutout + Cname + \"_mask.npy\").astype(\"f4\")\n",
    "                    sig = np.load(Path_to_cutout + Cname + \"_sigma.npy\").astype(\"f4\")\n",
    "                    ## Clear cache\n",
    "                    clear_download_cache()\n",
    "                    ###\n",
    "                    PSFname = psf_path + Nc[i] + '-grizli-' + Nv[i] + '-' + F + '_drc_cat_star'\n",
    "                    psf_raw = fits.open(PSFname + '_psf.psf')\n",
    "                    ###\n",
    "                    psf = psf_raw[1].data[0][0][0].astype(\"f4\")\n",
    "                    if (len(psf) - len(mask) > 0):\n",
    "                        Np = len(psf) - len(mask)\n",
    "                        if Np == 1:\n",
    "                            lim1 = int(0.5*Np)+1\n",
    "                        else: lim1 = int(0.5*Np)\n",
    "                    else: \n",
    "                        Np=0\n",
    "                    # Normalize resized PSF\n",
    "                    psf = psf[lim1-1:len(psf)-lim1-1,lim1-1:len(psf)-lim1-1]/np.sum(psf[lim1-1:len(psf)-lim1-1, lim1-1:len(psf)-lim1-1])\n",
    "                    print('size difference between psf and mask was', Np)\n",
    "                    # Start defyining which method needs to be used in order to calculate sizes\n",
    "                    if plot_im_mask_psf == True:\n",
    "                        fig, ax = plot_image(image, mask, sig, psf)\n",
    "                    try: \n",
    "                        check_input_data(data = image, rms = sig, psf = psf, mask = mask)\n",
    "                    except Warning:\n",
    "                        print(f'pysersic.exceptions.RMSWarning: Source{Cname} got invalid StudentT distribution')\n",
    "                        continue\n",
    "                    ## Choose the profile type    \n",
    "                    # profile = 'auto_multi'\n",
    "                    ## --- Set autoprior ---\n",
    "                    if prior_sel == False and prior_type == 'auto_single':\n",
    "                        prior = autoprior(image = image, profile_type = profile, mask = mask, sky_type = 'none')\n",
    "                        fitter = FitSingle(data = image, rms = sig, mask = mask, psf = psf, prior = prior, loss_func = student_t_loss)\n",
    "                    elif prior_sel == True and prior_type == 'auto_single': \n",
    "                        sky_med, sky_std, n_pix = estimate_sky(image=image, mask = mask)\n",
    "                        sky_med_unc = sky_std/np.sqrt(n_pix) \n",
    "                        ## --- Set custom prior --- ##\n",
    "                        ##############################\n",
    "                        custom_prior = PySersicSourcePrior(profile_type = profile, sky_type= 'none', sky_guess=sky_med, sky_guess_err= 2*sky_med_unc)\n",
    "                        ## --- Assume pixel size has 0.04\"/pixel. It needs to be modified upon occasion\n",
    "                        xc = imsize[i][k]/0.04*0.5\n",
    "                        yc = imsize[i][k]/0.04*0.5\n",
    "                        # #  --- This can be extended by the user, both in filters and fields. GDS and GDN have 0.02\"/pixel,\n",
    "                        ##       thus if the imsizeis not normalized, the center is will be shifted \n",
    "                        # if (Nc[i] == 'gds' or Nc[i] == 'gdn') and (F == 'f200w-clear' or F == 'f150w-clear'):\n",
    "                        #     xc = 2*xc\n",
    "                        #     yc = 2*yc\n",
    "                        \n",
    "                        ## ------- Reasonable value for the flux --------- ##\n",
    "                        cat, seg = sep.extract(image, thresh = 3., err = sig, segmentation_map = True,)\n",
    "                        if len(cat['a'])==0 or len(cat['flux'])==0:\n",
    "                            continue\n",
    "                        flux_guess = cat['flux'][0]\n",
    "                        sem_maj_axis = cat['a'][0]\n",
    "                        custom_prior.set_gaussian_prior('r_eff', sem_maj_axis, 0.4*sem_maj_axis)\n",
    "                        custom_prior.set_gaussian_prior('flux', flux_guess, 0.4*flux_guess)\n",
    "                        custom_prior.set_gaussian_prior('xc', xc, 2)\n",
    "                        custom_prior.set_gaussian_prior('yc', yc, 2)\n",
    "                        custom_prior.set_uniform_prior('n', 0.5, 9.0)\n",
    "                        custom_prior.set_uniform_prior('ellip', 0.0, 1.0)\n",
    "                        custom_prior.set_uniform_prior('theta', 0, 2*np.pi)\n",
    "    \n",
    "                        rkey, subkey = jax.random.split(rkey)\n",
    "                        fitter = FitSingle(data = image, rms = sig, mask = mask, psf = psf, prior = custom_prior, loss_func = student_t_loss)\n",
    "                    elif prior_sel == False and prior_type == 'auto_multi':\n",
    "                        ## --- Multi-source modeling --- ##\n",
    "                        sky_med, sky_std, n_pix = estimate_sky(image=image, mask = mask)\n",
    "                        sky_med_unc = sky_std/np.sqrt(n_pix) \n",
    "                        type_list = []\n",
    "                        c = round(len(sig)*0.5)\n",
    "                        objs,smap = sep.extract(image, 2, err = sig, segmentation_map = True,  deblend_cont=5e-5)\n",
    "                        to_pysersic = {}\n",
    "                        to_pysersic['flux'] = objs['flux']\n",
    "                        to_pysersic['x'] = objs['x']\n",
    "                        to_pysersic['y'] = objs['y']\n",
    "                        to_pysersic['r'] = objs['a']\n",
    "                        objs = smap[c,c]       \n",
    "                        # If a source is identified as extended, choose the fitting profile with \"profile\" variable\n",
    "                        for j in range(len(to_pysersic['x'])):\n",
    "                            if to_pysersic['flux'][j] < 0:\n",
    "                                type_list.append('pointsource')\n",
    "                            else:\n",
    "                                type_list.append(profile)\n",
    "                        to_pysersic['type'] = type_list\n",
    "                        # ------------------------------------\n",
    "                        prior = PySersicMultiPrior(catalog = to_pysersic, sky_type = 'none', \n",
    "                                            sky_guess = sky_med, sky_guess_err = 2*sky_med_unc)\n",
    "                        fitter = FitMulti(data = image, rms= sig, psf = psf, prior = prior)\n",
    "\n",
    "                    try :\n",
    "                        map_params = fitter.find_MAP(rkey = rkey) # To be given as output with some flag selection?\n",
    "                        #output_samp[Nc[i]][Cname].append(map_params)\n",
    "                        if plot_resid == True:\n",
    "                            fig, ax = plot_residual(image, map_params['model'], mask = mask, vmin = -1, vmax = 1)\n",
    "                            plt.savefig(directory_name+'/'+Cname+'.pdf')\n",
    "                        else:\n",
    "                            fig, ax = plot_residual(image, map_params['model'], mask = mask, vmin = -1, vmax = 1)\n",
    "                            plt.savefig(directory_name+'/'+Cname+'.pdf')\n",
    "                            plt.close(fig)\n",
    "                    except ValueError:\n",
    "                        print(f'Source{Cname} got invalid StudentT distribution')\n",
    "                        continue\n",
    "                    # Heavy version of the previous one: if user does not have timing issues\n",
    "                \n",
    "                    if quick_size == False:\n",
    "                        # for speed, in bulge-disk separation use svi-method\n",
    "                        if profile == 'sersic_exp' or profile == 'doublesersic':\n",
    "                            res = fitter.estimate_posterior(rkey=PRNGKey(1001), method=\"laplace\")\n",
    "                            summary = fitter.svi_results.summary()\n",
    "                            fitter.svi_results.save_result(f'{asdf_store_name}/{Cname}.asdf')\n",
    "                        else:\n",
    "                            fitter.sample(rkey = rkey)\n",
    "                            sampling_res = fitter.sampling_results\n",
    "                            fitter.sampling_results.save_result(f'{asdf_store_name}/{Cname}.asdf')\n",
    "                        #sampling_res.summary()\n",
    "            # ## Clear cache at every filter step    \n",
    "            # clear_download_cache()\n",
    "            # ##\n",
    "        end = time.time()\n",
    "        length = end - start\n",
    "        print('Size calculation has implied ', length/60, ' minutes to run')\n",
    "        \n",
    "    def FitBands(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, psf_path, wvList, n_order, plot_fits, plot_resid, prior_sel, Path_to_cutout, profile):\n",
    "    #P = CalcSize.GetSize(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, psf_path, Path_to_cutout)\n",
    "        wv_list = wvList\n",
    "        start = time.time()\n",
    "        ra = RA\n",
    "        dec = DEC\n",
    "        imsize = IMSIZE\n",
    "        output_samp = {}\n",
    "        if len(ra) != len(dec) or len(ra) != len(imsize):\n",
    "            warnings.warn('Size of RA, DEC or IMSIZE do not correspond. It must be len(RA) = len(DEC) = len(IMSIZE).')\n",
    "        if len(Nc) == 1 and len(RA) != 1:\n",
    "            ra = np.array([RA])\n",
    "        if len(Nc) == 1 and len(DEC) != 1:\n",
    "            dec = np.array([DEC]) \n",
    "        if len(Nc) == 1 and len(IMSIZE) != 1:\n",
    "            imsize = np.array([IMSIZE]) \n",
    "        if len(Nc) == 1 and len(Nfilter) != 1:\n",
    "            Nfilter = np.array([Nfilter])\n",
    "            \n",
    "        fitter_dict = {}\n",
    "        ind_res_dict = {}\n",
    "        sort_wv_list = []\n",
    "        aux_wv_list = []\n",
    "        cwd = os.getcwd()\n",
    "\n",
    "        directory_name = '/work3/s240096/DTU_project/fitted_bands_hom'\n",
    "        try:\n",
    "            os.makedirs(f'{directory_name}')\n",
    "            print(f\"Directory '{directory_name}' created successfully.\")\n",
    "        except FileExistsError:\n",
    "            print(f\"Directory '{directory_name}' already exists.\")\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        asdf_store_name = '/work3/s240096/DTU_project/asdf_files_multi'\n",
    "        try:\n",
    "            os.makedirs(asdf_store_name)\n",
    "            print(f\"Directory asdf_files created successfully.\")\n",
    "        except FileExistsError:\n",
    "            print(f\"Directory asdf_files already exists.\")\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied: Unable to create asdf_files.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        #######################################################\n",
    "        ## Comment the following line if files already exist ##\n",
    "        #######################################################\n",
    "        im = CalcSize.GetExpWht(N0, Nc, Nv, Nfilter, RA, DEC, IMSIZE, Path_to_cutout)\n",
    "        for i in range(len(Nc)):\n",
    "            aux_wv_list.append([str(np.round( np.array(wvList[i][b])*100 )) for b, band in enumerate(wvList[i])])\n",
    "            \n",
    "            for j in range(len(Nfilter[i])):\n",
    "                F = Nfilter[i][j]\n",
    "                f = aux_wv_list[i][j]\n",
    "                # F and f should have corresponding ordering of filters. The first filter in the list will be used as prior for the fitting\n",
    "                ###\n",
    "                fitter_dict[f] = {} \n",
    "                ind_res_dict[f] = {} \n",
    "                ###\n",
    "                rkey = jax.random.PRNGKey(5+3*j)\n",
    "                for k in range(len(ra[i])):\n",
    "                    Cname = F + '_' + str(ra[i][k]) +'_'+ str(dec[i][k])\n",
    "                    # Load image\n",
    "                    ##############################################################\n",
    "                    ## Comment the following line if cutout files already exist ##\n",
    "                    ##############################################################\n",
    "                    image = im['sci'][Nc[i]][F][k][0][0].data.astype(\"f4\")\n",
    "                    ##################################################################\n",
    "                    ## Uncomment the following two lines if the files already exist ##\n",
    "                    ##################################################################\n",
    "                    # image = fits.open(Path_to_cutout + Cname + '_' + 'sci' + '.fits')\n",
    "                    # image = image[0].data.astype('f4')\n",
    "                    #---------------------------------\n",
    "                    # Load mask and sigma\n",
    "                    mask = np.load(Path_to_cutout + Cname + '_mask.npy').astype(\"f4\")\n",
    "                    sig = np.load(Path_to_cutout + Cname + \"_sigma.npy\").astype(\"f4\")\n",
    "                    ## Clear cache\n",
    "                    clear_download_cache()\n",
    "                    ##\n",
    "                    # Load PSF\n",
    "                    PSFname = psf_path + Nc[i] + '-grizli-' + Nv[i] + '-' + F + '_drc_cat_star'\n",
    "                    psf_raw = fits.open(PSFname + '_psf.psf')\n",
    "                    psf = psf_raw[1].data[0][0][0].astype(\"f4\")\n",
    "                    ## BETA: MAYBE AVERAGING THE PSF IS NOT OK FOR REDUCING SIZE\n",
    "                    # if (Nc[i] == 'gds' or Nc[i] == 'gdn') and (F == 'f200w-clear' or F == 'f150w-clear'):\n",
    "                    #     # Ensure all arrays are float to avoid integer division\n",
    "                    #     psf = psf.astype(\"f4\")\n",
    "                    #     mask = mask.astype(\"f4\")\n",
    "                    #     sig = sig.astype(\"f4\")\n",
    "                    #     image = image.astype(\"f4\")\n",
    "                        \n",
    "                    #     # Resize all arrays using block_reduce\n",
    "                    #     resized_psf = block_reduce(psf, block_size=(2, 2), func=np.mean)\n",
    "                    #     resized_mask = block_reduce(mask, block_size=(2, 2), func=np.mean)\n",
    "                    #     resized_sig = block_reduce(sig, block_size=(2, 2), func=np.mean)\n",
    "                    #     resized_image = block_reduce(image, block_size=(2, 2), func=np.mean)\n",
    "                        \n",
    "                    #     # Normalize if needed\n",
    "                    #     psf = resized_psf[1:len(resized_psf), 1:len(resized_psf)] / np.sum(resized_psf[1:len(resized_psf), 1:len(resized_psf)])\n",
    "                        \n",
    "                    #     if len(resized_mask)%2 == 0:\n",
    "                    #         mask = resized_mask[1:len(resized_mask), 1:len(resized_mask)].copy(order='C')\n",
    "                    #         sig = resized_sig[1:len(resized_sig), 1:len(resized_sig)].copy(order='C')\n",
    "                    #         image = resized_image[1:len(resized_image), 1:len(resized_image)].copy(order='C')\n",
    "                    #     else:\n",
    "                    #         mask = resized_mask.copy(order='C')\n",
    "                    #         sig = resized_sig.copy(order='C')\n",
    "                    #         image = resized_image.copy(order='C')\n",
    "\n",
    "                    # else:\n",
    "                    if (len(psf) - len(mask) > 0):\n",
    "                        Np = len(psf) - len(mask)\n",
    "                        if Np == 1:\n",
    "                            lim1 = int(0.5*Np)+1\n",
    "                        else: lim1 = int(0.5*Np)\n",
    "                    else: \n",
    "                        Np = 0\n",
    "                    psf = psf[lim1-1:len(psf)-lim1-1,lim1-1:len(psf)-lim1-1]/np.sum(psf[lim1-1:len(psf)-lim1-1, lim1-1:len(psf)-lim1-1])\n",
    "                    print('size difference between psf and mask was', Np)\n",
    "                    \n",
    "                    pix_size = 0.04/3600    \n",
    "                    if (Nc[i] == 'gds' or Nc[i] == 'gdn') and (F == 'f200w-clear' or F == 'f150w-clear'):\n",
    "                            pix_size = pix_size/2.0\n",
    "\n",
    "                    if prior_sel == False:\n",
    "                        prior = autoprior(image = image, profile_type = profile, mask = mask, sky_type = 'none')\n",
    "                        fitter_cur = FitSingle(\n",
    "                                data = image,\n",
    "                                rms = sig,\n",
    "                                psf = psf,\n",
    "                                prior = prior,\n",
    "                                mask = mask,\n",
    "                                loss_func = student_t_loss\n",
    "                                )    \n",
    "                    # Find priors for each band\n",
    "                    else: \n",
    "                        sky_med, sky_std, n_pix = estimate_sky(image = image, mask = mask)\n",
    "                        sky_med_unc = sky_std/np.sqrt(n_pix) \n",
    "                        custom_prior = PySersicSourcePrior(profile_type = 'sersic', sky_type= 'flat', sky_guess=sky_med, sky_guess_err= 2*sky_med_unc)\n",
    "                        ## ------- Reasonable value for the flux --------- ##\n",
    "                        if image.dtype != \"f4\":\n",
    "                            image == image.astype(\"f4\")\n",
    "                        if sig.dtype != \"f4\":\n",
    "                            sig == sig.astype(\"f4\")\n",
    "                        if mask.dtype != \"f4\":\n",
    "                            mask == mask.astype(\"f4\")\n",
    "                        if psf.dtype != \"f4\":\n",
    "                            psf == psf.astype(\"f4\")\n",
    "                        if any(dtype != 'f4' for dtype in [image.dtype, sig.dtype, mask.dtype, psf.dtype]):\n",
    "                            continue\n",
    "                        cat, seg = sep.extract(image, thresh=3., err = sig, segmentation_map= True,)\n",
    "                        #########################################\n",
    "                        xc = imsize[i][k]/0.04*0.5\n",
    "                        yc = imsize[i][k]/0.04*0.5\n",
    "                        # if (Nc[i] == 'gds' or Nc[i] == 'gdn') and (F == 'f200w-clear' or F == 'f150w-clear'):\n",
    "                        #     xc = 2*xc\n",
    "                        #     yc = 2*yc\n",
    "                        # PRIOR SET\n",
    "                        ## ------- Reasonable value for the flux --------- ##\n",
    "                        if len(cat['a'])==0 or len(cat['flux'])==0:\n",
    "                            continue\n",
    "                        flux_guess = cat['flux'][0]\n",
    "                        sem_maj_axis = cat['a'][0]\n",
    "                        custom_prior.set_gaussian_prior('r_eff', sem_maj_axis, 0.3*sem_maj_axis)\n",
    "                        custom_prior.set_gaussian_prior('flux', flux_guess, 0.3*flux_guess)\n",
    "                        custom_prior.set_gaussian_prior('xc', xc, 2)\n",
    "                        custom_prior.set_gaussian_prior('yc', yc, 2)\n",
    "                        custom_prior.set_uniform_prior('n', 0.5, 9.)\n",
    "                        custom_prior.set_uniform_prior('ellip', 0., 1.)\n",
    "                        custom_prior.set_uniform_prior('theta', 0., 2*np.pi)\n",
    "                        prior_dict = autoprior(image = image, profile_type = profile, mask = mask, sky_type = 'flat')\n",
    "                        #########\n",
    "                        rkey = jax.random.PRNGKey(5+3*k)\n",
    "                        rkey,_ = jax.random.split(rkey, 2) # use different random number key for each run\n",
    "                        ##\n",
    "                        fitter_cur = FitSingle(\n",
    "                                data = image,\n",
    "                                rms = sig,\n",
    "                                psf = psf,\n",
    "                                prior = custom_prior,\n",
    "                                mask = mask,\n",
    "                                loss_func = student_t_loss\n",
    "                                )\n",
    "                    \n",
    "                    # Parameters for each pairs of coordinates(source), given the field\n",
    "                    print(f'Running fit - {Cname}')\n",
    "                    try:\n",
    "                        ind_res_cur = fitter_cur.estimate_posterior(method = 'svi-flow', rkey = rkey)\n",
    "                        fitter_cur.svi_results.save_result(f'{asdf_store_name}/{Cname}.asdf')\n",
    "                    except ValueError:\n",
    "                        print(f'Source{Cname} got invalid StudentT distribution')\n",
    "                        continue\n",
    "                    except RuntimeError:\n",
    "                        print('RunTime error: no suitable initial parameters')\n",
    "                        continue\n",
    "                    fitter_dict[f][k] = []\n",
    "                    ind_res_dict[f][k] = []\n",
    "                    ind_res_dict[f][k].append(ind_res_cur.retrieve_med_std())\n",
    "                    fitter_dict[f][k].append(fitter_cur)\n",
    "                ###\n",
    "                    \n",
    "        ###########################\n",
    "        ####### ALL BANDS #########\n",
    "        ## The following section is commented because pysersic does not deal with images having different pixel size.\n",
    "        ##  Even if normalized to same pixel size, if each image in the sequence has different arcsec size per pixel, \n",
    "        ##                                                        the fit will be mislead (N pixels in 0.02\" do not correspond to N pixels at 0.04\") \n",
    "        ###########################\n",
    "        # Uncomment the following block to allow for stacking in multiple filters and start fitting\n",
    "        # for i in range(len(Nc)): # i->l\n",
    "        #     for m in range(len(ra[i])): # k->m\n",
    "        #         ### Verify if the source has been fitted and fit has been successful\n",
    "        #         check_var = 0\n",
    "        #         for f, filter_name in enumerate(aux_wv_list[i]):\n",
    "        #             if filter_name not in ind_res_dict or not isinstance(ind_res_dict[filter_name], dict) or m not in ind_res_dict[filter_name]:\n",
    "        #                 check_var = 1\n",
    "        #         if check_var == 1:\n",
    "        #             continue\n",
    "        #         ### Continue(Skip source) if it did not\n",
    "        #         Cname_all = Nc[i] + '_' + str(ra[i][m]) + '_' + str(dec[i][m])\n",
    "        #         fig, axes = plt.subplots(1, 3, figsize = (10,3))\n",
    "        #         fig.suptitle(Cname_all, fontsize = 10)\n",
    "        #         ###\n",
    "        #         for n, param in enumerate(['n', 'ellip', 'r_eff']):# j->n\n",
    "        #             ax = axes[n]\n",
    "        #             if param == 'r_eff':\n",
    "        #                 med_ind = [ind_res_dict[f][m][0][param][0] for f in aux_wv_list[i]]\n",
    "        #                 err_ind = [ind_res_dict[f][m][0][param][1] for f in aux_wv_list[i]]\n",
    "        #                 plt.plot(wv_list[i], med_ind, color = 'red', ls = '-')\n",
    "        #                 ax.errorbar(wv_list[i], med_ind, yerr = err_ind, fmt = 'o', color = 'k',\n",
    "        #                             label = 'Ind.', ms = 8, capsize = 3, markeredgecolor = 'k', markerfacecolor = 'red', markeredgewidth = 1.1, ls='-')\n",
    "        #             else:\n",
    "        #                 med_ind = [ind_res_dict[f][m][0][param][0] for f in aux_wv_list[i]]\n",
    "        #                 err_ind = [ind_res_dict[f][m][0][param][1] for f in aux_wv_list[i]]\n",
    "        #                 ax.errorbar(wv_list[i], med_ind, yerr = err_ind, fmt = 'o', color = 'k',\n",
    "        #                             label = 'Ind.', ms = 8, capsize = 3, markeredgecolor = 'k', markerfacecolor = 'red', markeredgewidth = 1.1, ls='-')\n",
    "                        \n",
    "        #             axes[0].legend()\n",
    "        #             if param == 'n':\n",
    "        #                 param_latex = r'$n$'\n",
    "        #             elif param == 'ellip':\n",
    "        #                 param_latex = r'$1-q$'\n",
    "        #             elif param == 'r_eff':\n",
    "        #                 param_latex = r'$R_e(\\mathrm{kpc}$)'\n",
    "        #             ax.set_title(param_latex, fontsize = 14)\n",
    "        #             ax.set_xlabel(r'Obs. $\\lambda\\:\\mathrm{(\\mu m)}$')\n",
    "                \n",
    "        #         plt.tight_layout()\n",
    "        #         plt.savefig(directory_name+'/'+Cname_all+'.pdf')\n",
    "                \n",
    "                \n",
    "        #         wv_to_save = np.linspace(min(wv_list[i]), max(wv_list[i]), num = 50)\n",
    "        #         print(f'Running fit - {Cname_all}')\n",
    "        #         try: \n",
    "        #             MultiFitter = FitMultiBandPoly(fitter_list = [fitter_dict[F][m][0] for F in aux_wv_list[i]],\n",
    "        #                                             wavelengths = wv_list[i],\n",
    "        #                                             band_names = Nfilter[i],\n",
    "        #                                             linked_params = ['n','ellip','r_eff'],\n",
    "        #                                             const_params = ['xc','yc','theta'],\n",
    "        #                                             wv_to_save = wv_to_save,\n",
    "        #                                             poly_order = n_order)\n",
    "        #         except ValueError:\n",
    "        #             print(f'Source{Cname_all} got invalid StudentT distribution')\n",
    "        #             continue\n",
    "                    \n",
    "        #         rkey = jax.random.PRNGKey(5+3*m)\n",
    "        #         rkey, subkey = jax.random.split(rkey)\n",
    "        #         print(f'Estimating posterior - {Cname_all}')\n",
    "        #         try:\n",
    "        #             multires = MultiFitter.estimate_posterior(method = 'svi-flow', rkey = rkey)\n",
    "        #         except TypeError:\n",
    "        #             print('Something wrong in concatenation?')\n",
    "        #             continue\n",
    "        #         except RuntimeError:\n",
    "        #             print('RunTime error: no suitable initial parameters')\n",
    "        #             continue\n",
    "                \n",
    "        #         #########\n",
    "        #         link_params = [f'{param}_{b}' for b in Nfilter[i] for param in ['n','ellip','r_eff']] # Look at posteriors of \"linked\" parameters\n",
    "        #         multi_res_dict = multires.retrieve_med_std()\n",
    "        #         az.summary(multires.idata, var_names=link_params)\n",
    "        #         #########\n",
    "        #         if plot_fits == True:    \n",
    "        #             fig, axes = plt.subplots(1,3, figsize = (10,3))\n",
    "        #             fig.suptitle(Cname_all, fontsize = 10)\n",
    "        #             for s,param in enumerate(['n','ellip','r_eff']):\n",
    "        #                 ax = axes[s]\n",
    "                        \n",
    "        #                 med_ind = [ind_res_dict[f][m][0][param][0] for f in aux_wv_list[i]]\n",
    "        #                 err_ind = [ind_res_dict[f][m][0][param][1] for f in aux_wv_list[i]]\n",
    "                \n",
    "        #                 med_multi = [multi_res_dict[f'{param}_{b}'][0] for b in Nfilter[i]]\n",
    "        #                 err_multi = [multi_res_dict[f'{param}_{b}'][1] for b in Nfilter[i]]\n",
    "                \n",
    "        #                 ax.errorbar(wv_list[i], med_ind, yerr=err_ind, fmt = 'o', color = 'k', label = 'Ind. fit')\n",
    "        #                 ax.errorbar(np.array(wv_list[i])+0.01, med_multi, yerr=err_multi, fmt = 'o', color = 'C0', label = 'Joint fit')\n",
    "        #                 param_smooth = multires.idata.posterior[f'{param}_at_wv'].data.squeeze()\n",
    "        #                 ax.plot(wv_to_save, param_smooth[:20].T, 'C0-', alpha = 0.2)\n",
    "        #                 if param == 'n':\n",
    "        #                     param_latex = r'$n$'\n",
    "        #                 elif param == 'ellip':\n",
    "        #                     param_latex = r'$1-q$'\n",
    "        #                 elif param == 'r_eff':\n",
    "        #                     param_latex = r'$R_e$(pixels)'\n",
    "        #                 ax.set_title(param_latex, fontsize = 14)\n",
    "        #                 ax.set_xlabel(r'Obs. $\\lambda\\:\\mathrm{(\\mu m)}$')\n",
    "        #             axes[0].legend()\n",
    "        #             plt.tight_layout()\n",
    "        #             plt.savefig(directory_name+'/'+Cname_all+'.pdf')\n",
    "        #         else:\n",
    "        #             fig, axes = plt.subplots(1,3, figsize = (10,3))\n",
    "        #             fig.suptitle(Cname_all, fontsize = 10)\n",
    "        #             for s,param in enumerate(['n','ellip','r_eff']):\n",
    "        #                 ax = axes[s]\n",
    "        #                 med_ind = [ind_res_dict[f][m][0][param][0] for f in aux_wv_list[i]]\n",
    "        #                 err_ind = [ind_res_dict[f][m][0][param][1] for f in aux_wv_list[i]]\n",
    "                \n",
    "        #                 med_multi = [multi_res_dict[f'{param}_{b}'][0] for b in Nfilter[i]]\n",
    "        #                 err_multi = [multi_res_dict[f'{param}_{b}'][1] for b in Nfilter[i]]\n",
    "                \n",
    "        #                 ax.errorbar(wv_list[i], med_ind, yerr=err_ind, fmt = 'o', color = 'k', label = 'Ind. fit')\n",
    "        #                 ax.errorbar(np.array(wv_list[i])+0.01, med_multi, yerr=err_multi, fmt = 'o', color = 'C0', label = 'Joint fit')\n",
    "        #                 param_smooth = multires.idata.posterior[f'{param}_at_wv'].data.squeeze()\n",
    "        #                 ax.plot(wv_to_save, param_smooth[:20].T, 'C0-', alpha = 0.2)\n",
    "        #                 if param == 'n':\n",
    "        #                     param_latex = r'$n$'\n",
    "        #                 elif param == 'ellip':\n",
    "        #                     param_latex = r'$1-q$'\n",
    "        #                 elif param == 'r_eff':\n",
    "        #                     param_latex = r'$R_e$(pixels)'\n",
    "        #                 ax.set_title(param_latex, fontsize = 14)\n",
    "        #                 ax.set_xlabel(r'Obs. $\\lambda\\:\\mathrm{(\\mu m)}$')\n",
    "        #             axes[0].legend()\n",
    "        #             plt.tight_layout()\n",
    "        #             plt.savefig(directory_name+'/'+Cname_all+'.pdf')\n",
    "        #             plt.close(fig)\n",
    "                    \n",
    "        # return ind_res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2cfb6-2d64-4163-a712-8f27d6e9114c",
   "metadata": {},
   "source": [
    "# Definition of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88e4a09-0a9d-4913-9503-1061f1dc448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678b03a5-f05b-4f8d-8cf0-d65cd4c094a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "posVec = pd.read_csv(f'/work3/s240096/DTU_project/SED_selctedGal_{chi2}_cut9.csv')\n",
    "RA = posVec['RA(deg)']\n",
    "DEC = posVec['DEC(deg)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee2de69-7927-4955-91e7-dbf287132a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "######### REMEMBER ######### \n",
    "# to check the location of PSF and zout/phot_corr files\n",
    "N0 = 'https://s3.amazonaws.com/grizli-v2/JwstMosaics/v7/' # Specify path beforehand\n",
    "Path_to_cutout = '/work3/s240096/DTU_project/cutouts_multisource/cutout_'\n",
    "# List of the fields\n",
    "ra = {}\n",
    "dec = {}\n",
    "Nc = ['ceers-full', 'gds', 'primer-uds-north', 'primer-uds-south', 'primer-cosmos-east', 'primer-cosmos-west', 'gdn']\n",
    "counter = 0\n",
    "for i in range(len(Nc)):\n",
    "    ra[Nc[i]] = []\n",
    "    dec[Nc[i]] = []\n",
    "    lst = os.listdir(f\"/work3/s240096/DTU_project/SEDs_Chi{chi2}_{Nc[i]}/good_SED\") # your directory path\n",
    "    number_files = len(lst)\n",
    "    for j in range(counter, counter+number_files):\n",
    "        ra[Nc[i]].append(RA[j])\n",
    "        dec[Nc[i]].append(DEC[j])\n",
    "    #print(bool(ra[Nc[i]] == list(RA[counter:counter+number_files])))\n",
    "    counter = counter + number_files\n",
    "# # Only one version specified for each field. Since PSF is made for different versions\n",
    "Nv = ['v7.2', 'v7.2', 'v7.2', 'v7.2', 'v7.0', 'v7.0', 'v7.3']\n",
    "# # type list(). Filters are to be inserted keeping in mind that the first one wills erve as prior for the multi-band fit\n",
    "Nf = ['f200w-clear', 'f444w-clear']\n",
    "#Nf = ['f150w-clear', 'f200w-clear', 'f277w-clear', 'f356w-clear', 'f444w-clear']\n",
    "Nfilter = [Nf, Nf, Nf, Nf, Nf, Nf, Nf] \n",
    "# To use more coordinates: cycle over a pre-selected vector. Also the following are list-type variables. Insert one list for each field.\n",
    "CoRA = []\n",
    "CoDEC = []\n",
    "for i in range(len(Nc)):\n",
    "    CoRA.append(ra[Nc[i]])\n",
    "    CoDEC.append(dec[Nc[i]])\n",
    "# Code is robust enough to deal with null IMSIZE, but it takes more time: in case of criticity, use it.\n",
    "stand_imsize = 3 # in arcseconds\n",
    "IMSIZE = []\n",
    "for i in range(len(Nc)):\n",
    "        IMSIZE.append(list(stand_imsize + np.zeros(len(ra[Nc[i]]))))\n",
    "psf_path = '/work3/s240096/psf_cat/'\n",
    "WSubList = [1.50, 2.00, 2.77, 3.56, 4.44]\n",
    "wvList = [WSubList, WSubList, WSubList, WSubList, WSubList, WSubList, WSubList] #micrometers\n",
    "# Load only science image(_sci.fits) for testing!\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97fce5-9f2c-4269-931a-82256628ff27",
   "metadata": {},
   "source": [
    "# Compute sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7ff87e-dad5-4b54-b3be-9770cefbd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cutouts: mask, sigma, fits ####\n",
    "# for K in range(1, len(Nc)):\n",
    "#     Tsize = CalcSize.GetExpWht(N0, [Nc[K]], [Nv[K]], [Nfilter[K]], [CoRA[K]], [CoDEC[K]], [IMSIZE[K]], Path_to_cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7d2ec-4974-464d-9f34-3c9fc881ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Available prior types ---- #\n",
    "# 'auto_multi' : multi-source fit with Srsic profile\n",
    "# 'auto_single' : single source fit with Srsic profile\n",
    "#######################################################\n",
    "# ---- Common profile types ---- #\n",
    "# 'sersic' : classical Srsic\n",
    "# 'sersic_exp' : allows bulge-disk decomposition with n_disk = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d999e3-f4c6-42e5-8efa-1f8dea882892",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Size computation: single-band ####\n",
    "for K in range(len(Nc)):\n",
    "    CalcSize.GetSize(N0, [Nc[K]], [Nv[K]], [Nfilter[K]], [CoRA[K]], [CoDEC[K]], [IMSIZE[K]],\n",
    "                    psf_path, quick_size = False, plot_im_mask_psf = False, plot_resid = False, prior_sel = False, prior_type = 'auto_multi',\n",
    "                     Path_to_cutout = Path_to_cutout, profile = profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85d2cce3-4c8e-42e9-87c4-1aceb019bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Parameters computation: multi-band ####\n",
    "# for K in range(len(Nc)):\n",
    "#     CalcSize.FitBands(N0, [Nc[K]], [Nv[K]], [Nfilter[K]], [CoRA[K]], [CoDEC[K]], [IMSIZE[K]],\n",
    "#                                 psf_path, [wvList[K]], n, plot_fits = False, plot_resid = False, prior_sel = False,Path_to_cutout=Path_to_cutout, profile = 'sersic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
